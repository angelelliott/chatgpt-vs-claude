# Abstract

The generative AI revolution does not come without challenges. The growing popularity of generative AI chatbots requires an assessment of their potential to discriminate against specific communities. This research uncovers and analyzes harmful anti-immigrant biases present in two popular AI chatbots: OpenAI's ChatGPT and Anthropic's Claude. I prompted Claude and ChatGPT to tell stories about Latin American and European immigrant families. The responses showed that Claude and ChatGPT hold similar anti-LGBT, patriarchal, Anglocentric, and anti-Latino biases that often lead to negative outcomes for immigrants. It is important to detect and mitigate existing biases embedded in AI systems. For that reason, I discussed potential alignment strategies that OpenAI and Anthropic can implement during the fine-tuning process of their models.

# Overview of repository 

Rodriguez24.pdf --> Report written in LaTeX <br>
chatgpt-vs-claude.xlsx --> Datasets 
data_analysis.ipynb --> Notebook of visualizations
genai.sql --> Database management
