# Overview 
In this repository, I hold all the files concerning an experiment I conducted to assess Claude and ChatGPT's understanding of a complex and nuanced topic: immigration. 

# Overview of repository 

Rodriguez24.pdf --> Report written in LaTeX <br>
chatgpt-vs-claude.xlsx --> Datasets <br>
data_analysis.ipynb --> Notebook of visualizations <br>
genai.sql --> Database management <br>

# Abstract of report

The generative AI revolution does not come without challenges. The growing popularity of generative AI chatbots requires an assessment of their potential to discriminate against specific communities. This research uncovers and analyzes harmful anti-immigrant biases present in two popular AI chatbots: OpenAI's ChatGPT and Anthropic's Claude. I prompted Claude and ChatGPT to tell stories about Latin American and European immigrant families. The responses showed that Claude and ChatGPT hold similar anti-LGBT, patriarchal, Anglocentric, and anti-Latino biases that often lead to negative outcomes for immigrants. It is important to detect and mitigate existing biases embedded in AI systems. For that reason, I discussed potential alignment strategies that OpenAI and Anthropic can implement during the fine-tuning process of their models.

